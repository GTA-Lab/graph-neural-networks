{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmQcJgGH0TKw"
      },
      "source": [
        "# Including Node Features with MLP & GNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So far, we've focused on graph topology, but graph datasets often include additional features for nodes and edges, such as scores, colors, and words. Incorporating these features is crucial for creating effective embeddings. In this chapter, we'll introduce two new graph datasets: Cora and Facebook Page-Page. We'll explore how traditional Neural Networks perform on node features alone and then integrate topological information to develop our first Graph Neural Network (GNN) architecture. By comparing the two approaches, we'll highlight the benefits of combining node features and edges.\n",
        "\n",
        "By the end of this chapter, you'll learn to implement MLP and GNNs in PyTorch, embedding topological features into node representations to enhance model performance. Topics covered include:\n",
        "\n",
        "- Introducing graph datasets\n",
        "- Classifying nodes with vanilla neural networks (MLP)\n",
        "- Classifying nodes with vanilla graph neural networks (GNNs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introducing graph datasets\n",
        "\n",
        "The graph datasets we’re going to use in this chapter are richer than Zachary’s Karate Club: they have more nodes, more edges, and include node features. In this section, we will introduce them to give us a good understanding of these graphs and how to process them with PyTorch Geometric. Here \n",
        "are the two datasets we will use:\n",
        "\n",
        "* The Cora dataset\n",
        "* The Facebook Page-Page dataset\n",
        "\n",
        "### Cora dataset\n",
        "\n",
        "Let’s start with the smaller one: the popular Cora dataset from [Planetoid](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.datasets.Planetoid.html).\n",
        "The Cora dataset is the most popular dataset for node classification in the scientific literature. It represents a network of 2,708 publications, where each connection is a \n",
        "reference. Each publication is described as a binary vector of 1,433 unique words, where 0 and 1 indicate the absence or presence of the corresponding word, respectively. This representation is also called a binary bag of words in natural language processing. Our goal is to classify each node into one of seven categories.\n",
        "\n",
        "The following figure is a plot of the Cora dataset made with [yEd Live](https://www.yworks.com/yed-live/). Nodes are corresponding to papers. Some papers are so interconnected that they form clusters. These clusters should be easier to classify than poorly connected nodes.\n",
        "\n",
        "![](img/CoraBalloons.png)\n",
        "\n",
        "\n",
        "Here, we are given the ground-truth labels of only a small subset of nodes, and want to infer the labels for all the remaining nodes (*transductive learning*).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoN3GTmw0CTs",
        "outputId": "c4b7ebbc-79d6-44d3-b448-7006f2b586f4",
        "tags": [
          "hide-cell"
        ]
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "# !pip install -q torch-scatter~=2.1.0 torch-sparse~=0.6.16 torch-cluster~=1.6.0 torch-spline-conv~=1.2.1 torch-geometric==2.2.0 -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMp_ertkDcJf",
        "outputId": "33e608a1-9e1e-4841-e835-20f5dff1b437"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: Cora()\n",
            "---------------\n",
            "Number of graphs: 1\n",
            "Number of nodes: 2708\n",
            "Number of edges: 10556\n",
            "Number of features: 1433\n",
            "Number of classes: 7\n",
            "\n",
            "Graph:\n",
            "------\n",
            "Average node degree: 3.90\n",
            "Number of training nodes: 140\n",
            "Training node label rate: 0.05\n",
            "Has isolated nodes: False\n",
            "Edges are directed: False\n",
            "Graph has isolated nodes: False\n",
            "Has self-loops: False\n",
            "Is undirected: True\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.datasets import Planetoid\n",
        "\n",
        "# Import dataset from PyTorch Geometric\n",
        "dataset = Planetoid(root=\"../../data\", name=\"Cora\")\n",
        "\n",
        "data = dataset[0]\n",
        "\n",
        "# Print information about the dataset\n",
        "print(f'Dataset: {dataset}')\n",
        "print('---------------')\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of nodes: {data.num_nodes}')\n",
        "print(f'Number of edges: {data.num_edges}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')\n",
        "\n",
        "# Print information about the graph\n",
        "print(f'\\nGraph:')\n",
        "print('------')\n",
        "\n",
        "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
        "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
        "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
        "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
        "print(f'Edges are directed: {data.is_directed()}')\n",
        "print(f'Graph has isolated nodes: {data.has_isolated_nodes()}')\n",
        "print(f'Has self-loops: {data.has_self_loops()}')\n",
        "print(f'Is undirected: {data.is_undirected()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The different subjects (classes) are:\n",
        "\n",
        "'Case_Based',\n",
        "'Genetic_Algorithms',\n",
        "'Neural_Networks',\n",
        "'Probabilistic_Methods',\n",
        "'Reinforcement_Learning',\n",
        "'Rule_Learning',\n",
        "'Theory'\n",
        "\n",
        "\n",
        "A typical ML challenges with this dataset in mind:\n",
        "\n",
        "- label prediction: predict the subject of a paper (node) on the basis of the surrounding node data and the structure of the graph\n",
        "- edge prediction: given node data, can one predict the papers that should be cited?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "AtFTuxGObVbX",
        "outputId": "1f78cb2a-0db3-4b03-d9fd-d1e8321b954c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>1424</th>\n",
              "      <th>1425</th>\n",
              "      <th>1426</th>\n",
              "      <th>1427</th>\n",
              "      <th>1428</th>\n",
              "      <th>1429</th>\n",
              "      <th>1430</th>\n",
              "      <th>1431</th>\n",
              "      <th>1432</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2703</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2704</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2705</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2706</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2707</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2708 rows × 1434 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0    1    2    3    4    5    6    7    8    9  ...  1424  1425  1426  \\\n",
              "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
              "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
              "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
              "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
              "4     0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
              "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   \n",
              "2703  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...   0.0   1.0   0.0   \n",
              "2704  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
              "2705  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
              "2706  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
              "2707  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
              "\n",
              "      1427  1428  1429  1430  1431  1432  label  \n",
              "0      0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
              "1      0.0   0.0   0.0   0.0   0.0   0.0      4  \n",
              "2      0.0   0.0   0.0   0.0   0.0   0.0      4  \n",
              "3      0.0   0.0   0.0   0.0   0.0   0.0      0  \n",
              "4      0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
              "...    ...   ...   ...   ...   ...   ...    ...  \n",
              "2703   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
              "2704   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
              "2705   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
              "2706   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
              "2707   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
              "\n",
              "[2708 rows x 1434 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_x = pd.DataFrame(data.x.numpy())\n",
        "df_x['label'] = pd.DataFrame(data.y)\n",
        "df_x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classifying nodes with vanilla neural networks (MLPs)\n",
        "\n",
        "Compared to Zachary’s Karate Club, these two datasets include a new type of information: node features. They provide additional information about the nodes in a graph, such as a user’s age, gender, or interests in a social network. In a vanilla neural network (also called multilayer perceptron), these embeddings are directly used in the model to perform downstream tasks such as node classification.\n",
        "In this section, we will consider node features as a regular tabular dataset. We will train a simple neural network on this dataset to classify our nodes. *Note that this architecture does not take into account the topology of the network*. We will try to fix this issue in the next section and compare our results\n",
        "\n",
        "If you’re familiar with machine learning, you probably recognize a typical dataset with data and labels. We can develop a simple Multilayer Perceptron (MLP) and train it on data.x with the labels provided by data.y.\n",
        "Let’s create our own MLP class with four methods:\n",
        "\n",
        "- __init__() to initialize an instance\n",
        "- forward() to perform the forward pass\n",
        "- fit() to train the model\n",
        "- test() to evaluate it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TensorFlow and PyTorch are two famouse deep learning libraries. In [Fall 2023 the deep learning course](https://fum-cs.github.io/dl/) of FUM-CS was based on TensorFlow, and in [Fall 2024](https://fum-cs.github.io/dl-fall2024), PyTorch is used in the mentioned course.\n",
        "The code here are based on PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.manual_seed(0)\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def accuracy(y_pred, y_true):\n",
        "    \"\"\"Calculate accuracy.\"\"\"\n",
        "    return torch.sum(y_pred == y_true) / len(y_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4iU8dx0DpFR",
        "outputId": "5e7ea7eb-873f-498c-b735-bc9873f8784d"
      },
      "outputs": [],
      "source": [
        "class MLP(torch.nn.Module):\n",
        "    \"\"\"Multilayer Perceptron\"\"\"\n",
        "    def __init__(self, dim_in, dim_h, dim_out):\n",
        "        super().__init__()\n",
        "        self.linear1 = Linear(dim_in, dim_h)\n",
        "        self.linear2 = Linear(dim_h, dim_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.linear2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    def fit(self, data, epochs):\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(self.parameters(),\n",
        "                                          lr=0.01,\n",
        "                                          weight_decay=5e-4)\n",
        "\n",
        "        self.train()\n",
        "        for epoch in range(epochs+1):\n",
        "            optimizer.zero_grad()\n",
        "            out = self(data.x)\n",
        "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "            acc = accuracy(out[data.train_mask].argmax(dim=1),\n",
        "                          data.y[data.train_mask])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if(epoch % 20 == 0):\n",
        "                val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
        "                val_acc = accuracy(out[data.val_mask].argmax(dim=1),\n",
        "                                  data.y[data.val_mask])\n",
        "                print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc:'\n",
        "                      f' {acc*100:>5.2f}% | Val Loss: {val_loss:.2f} | '\n",
        "                      f'Val Acc: {val_acc*100:.2f}%')\n",
        "\n",
        "    @torch.no_grad()      \n",
        "    def test(self, data):\n",
        "        self.eval()\n",
        "        out = self(data.x)\n",
        "        acc = accuracy(out.argmax(dim=1)[data.test_mask], data.y[data.test_mask])\n",
        "        return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP(\n",
            "  (linear1): Linear(in_features=1433, out_features=16, bias=True)\n",
            "  (linear2): Linear(in_features=16, out_features=7, bias=True)\n",
            ")\n",
            "Epoch   0 | Train Loss: 1.959 | Train Acc: 14.29% | Val Loss: 2.00 | Val Acc: 12.40%\n",
            "Epoch  20 | Train Loss: 0.110 | Train Acc: 100.00% | Val Loss: 1.46 | Val Acc: 49.40%\n",
            "Epoch  40 | Train Loss: 0.014 | Train Acc: 100.00% | Val Loss: 1.44 | Val Acc: 51.00%\n",
            "Epoch  60 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 1.40 | Val Acc: 53.80%\n",
            "Epoch  80 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 1.37 | Val Acc: 55.40%\n",
            "Epoch 100 | Train Loss: 0.009 | Train Acc: 100.00% | Val Loss: 1.34 | Val Acc: 54.60%\n",
            "\n",
            "MLP test accuracy: 53.40%\n"
          ]
        }
      ],
      "source": [
        "# Create MLP model\n",
        "mlp = MLP(dataset.num_features, 16, dataset.num_classes)\n",
        "print(mlp)\n",
        "\n",
        "# Train\n",
        "mlp.fit(data, epochs=100)\n",
        "\n",
        "# Test\n",
        "acc = mlp.test(data)\n",
        "print(f'\\nMLP test accuracy: {acc*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classifying nodes with Vanilla Graph Neural Network\n",
        "\n",
        "A Graph Neural Network (GNN) is a type of neural network designed to operate on graph-structured data. It learns to represent nodes and edges in a graph through message passing and aggregation techniques. Let's break down a simple GNN architecture, focusing on some core mathematical components, particularly the formulation involving weights.\n",
        "\n",
        "### Basics of Graph Representation\n",
        "\n",
        "In a graph $ G = (V, E) $:  \n",
        "\n",
        "- $ V $ is the set of nodes (vertices), $|V|=N$.  \n",
        "- $ E $ is the set of edges connecting these nodes.  \n",
        "\n",
        "### Node Features  \n",
        "\n",
        "Each node $ i \\in V $ has a feature vector $ \\mathbf{x}_i $ of dimension $ d $. If there are $ N $ nodes in the graph, we can represent the features of all nodes as a feature matrix $ \\mathbf{X} $:  \n",
        "\n",
        "$$  \n",
        "\\mathbf{X} \\in \\mathbb{R}^{N \\times d}  \n",
        "$$  \n",
        "\n",
        "### Weight Matrix  \n",
        "\n",
        "In GNNs, the weights are shared across all nodes, which is a key aspect that allows the model to generalize to different sizes and structures of graphs. The weight matrix $ \\mathbf{W} \\in \\mathbb{R}^{d \\times m} $ transforms the feature dimension from $ d $ to $ m $ (the output dimension).  \n",
        "\n",
        "### Node Representation Calculation  \n",
        "\n",
        "For a single node $ i $, the new representation after applying the weight matrix can be given as:  \n",
        "\n",
        "$$  \n",
        "\\mathbf{h}_i = \\mathbf{W}^T\\mathbf{x}_i   \n",
        "$$  \n",
        "\n",
        "Where:  \n",
        "- $ \\mathbf{h}_i \\in \\mathbb{R}^{m} $ is the new representation of node $ i $.  \n",
        "- $ \\mathbf{x}_i \\in \\mathbb{R}^{d} $ is the feature vector of node $ i $.  \n",
        "- $ \\mathbf{W} \\in \\mathbb{R}^{d \\times m} $ is the weight matrix.  \n",
        "- $ \\mathbf{X} \\in \\mathbb{R}^{N \\times d}$ is the features of all nodes.\n",
        "In matrix form for all nodes:  \n",
        "\n",
        "$$  \n",
        "\\mathbf{H} = \\mathbf{X} \\mathbf{W}  \n",
        "$$  \n",
        "\n",
        "Where:  \n",
        "- $ \\mathbf{H} \\in \\mathbb{R}^{N \\times m} $ is the matrix of new node representations.  \n",
        "\n",
        "### Weight Sharing  \n",
        "\n",
        "The weight sharing comes from the fact that each $ \\mathbf{x}_i $ is transformed by the same weight matrix $ \\mathbf{W} $. This ensures that irrespective of the node being processed, the same transformation is applied, allowing for efficient training on various graph sizes.  \n",
        "\n",
        "### GNN Layer with Adjacency Matrix  \n",
        "\n",
        "A simple vanilla GNN layer can use the adjacency matrix $ \\mathbf{A} \\in \\mathbb{R}^{N \\times N}$ of the graph. The operation of a GNN Layer are as follows:  \n",
        "\n",
        "1. **Aggregation**: For each node, aggregate features from its neighbors. This can be done using matrix multiplication with the adjacency matrix:  \n",
        "\n",
        "$$  \n",
        "\\mathbf{H}^{(l)} = \\mathbf{A} \\mathbf{H}^{(l-1)}  \n",
        "$$  \n",
        "\n",
        "2. **Update**: Apply the weight transformation to the aggregated node features:  \n",
        "\n",
        "$$  \n",
        "\\mathbf{H}^{(l)} = \\sigma(\\mathbf{A} \\mathbf{H}^{(l-1)} \\mathbf{W}^{(l)})  \n",
        "$$  \n",
        "\n",
        "Where:\n",
        "- $ \\mathbf{H}^{(l)} $ represents the node features at layer $ l $.  \n",
        "- $ \\sigma $ is an activation function (e.g., ReLU).  \n",
        "- $ \\mathbf{W}^{(l)} $ is the weight matrix for layer $ l $. \n",
        "- $ \\mathbf{H}^{(0)} = X$. \n",
        "\n",
        "\n",
        "This operation allows each node to learn from its neighbors and update its representation iteratively across multiple layers.  \n",
        "\n",
        "For $l=1$, we have:\n",
        "$$  \n",
        "\\mathbf{H}^{(1)} = \\sigma(\\mathbf{A} \\mathbf{X} \\mathbf{W}^{(0)})  \n",
        "$$ \n",
        "\n",
        "Where:\n",
        " $\\mathbf{A} \\in \\mathbb{R}^{N \\times N}, \\mathbf{X} \\in \\mathbb{R}^{N \\times d}, \\mathbf{W}^{(0)} \\in \\mathbb{R}^{d \\times m} \\rightarrow \\mathbf{H}^{(1)}\\in \\mathbb{R}^{N \\times m}$\n",
        "\n",
        "## Summary  \n",
        "\n",
        "1. Each node has a feature vector $ \\mathbf{x}_i $ of dimension $ d $.  \n",
        "2. The combined feature matrix for all nodes is $ \\mathbf{X} \\in \\mathbb{R}^{N \\times d} $.  \n",
        "3. A weight matrix $ \\mathbf{W} \\in \\mathbb{R}^{d \\times m} $ transforms the features.  \n",
        "4. The adjacency matrix $ \\mathbf{A} $ is used to aggregate neighbors' information.  \n",
        "5. The new node representations can be calculated iteratively in a GNN layer as:  \n",
        "\n",
        "$$  \n",
        "\\mathbf{H}^{(l)} = \\sigma(\\mathbf{A} \\mathbf{H}^{(l-1)} \\mathbf{W}^{(l)})  \n",
        "$$  \n",
        "\n",
        "This framework builds the foundation for more complex operations in GNNs, including additional layers and techniques for handling diverse graph structures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "tags": [
          "hide-cell"
        ]
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.manual_seed(0)\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OTiqwwFXQlVA"
      },
      "outputs": [],
      "source": [
        "class VanillaGNNLayer(torch.nn.Module):\n",
        "    def __init__(self, dim_in, dim_out):\n",
        "        super().__init__()\n",
        "        self.linear = Linear(dim_in, dim_out, bias=False)\n",
        "\n",
        "    def forward(self, x, adjacency):\n",
        "        hw = self.linear(x)\n",
        "        ahw = torch.sparse.mm(adjacency, hw)\n",
        "        return ahw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9eP_1qtROua",
        "outputId": "540c47fe-d910-4dd4-b310-b96eaf03ffc1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([2708, 1433]), torch.Size([2708, 2708]))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch_geometric.utils import to_dense_adj\n",
        "\n",
        "adjacency = to_dense_adj(data.edge_index)[0]\n",
        "adjacency += torch.eye(len(adjacency))\n",
        "\n",
        "data.x.shape, adjacency.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmHhedhcK9vi",
        "outputId": "286ea8be-b6eb-4ec0-fb4e-6b23c9e68479"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VanillaGNN(\n",
            "  (gnn1): VanillaGNNLayer(\n",
            "    (linear): Linear(in_features=1433, out_features=16, bias=False)\n",
            "  )\n",
            "  (gnn2): VanillaGNNLayer(\n",
            "    (linear): Linear(in_features=16, out_features=7, bias=False)\n",
            "  )\n",
            ")\n",
            "Epoch   0 | Train Loss: 2.039 | Train Acc: 16.43% | Val Loss: 2.10 | Val Acc: 8.80%\n",
            "Epoch  20 | Train Loss: 0.025 | Train Acc: 100.00% | Val Loss: 2.20 | Val Acc: 74.40%\n",
            "Epoch  40 | Train Loss: 0.003 | Train Acc: 100.00% | Val Loss: 2.95 | Val Acc: 73.20%\n",
            "Epoch  60 | Train Loss: 0.001 | Train Acc: 100.00% | Val Loss: 3.04 | Val Acc: 73.80%\n",
            "Epoch  80 | Train Loss: 0.001 | Train Acc: 100.00% | Val Loss: 2.96 | Val Acc: 74.20%\n",
            "Epoch 100 | Train Loss: 0.001 | Train Acc: 100.00% | Val Loss: 2.89 | Val Acc: 74.40%\n",
            "\n",
            "GNN test accuracy: 75.10%\n"
          ]
        }
      ],
      "source": [
        "class VanillaGNN(torch.nn.Module):\n",
        "    \"\"\"Vanilla Graph Neural Network\"\"\"\n",
        "    def __init__(self, dim_in, dim_h, dim_out):\n",
        "        super().__init__()\n",
        "        self.gnn1 = VanillaGNNLayer(dim_in, dim_h)\n",
        "        self.gnn2 = VanillaGNNLayer(dim_h, dim_out)\n",
        "\n",
        "    def forward(self, x, adjacency):\n",
        "        ahw = self.gnn1(x, adjacency)\n",
        "        h = torch.relu(ahw)\n",
        "        ahw = self.gnn2(h, adjacency)\n",
        "        return F.log_softmax(ahw, dim=1)\n",
        "\n",
        "    def fit(self, data, epochs):\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(self.parameters(),\n",
        "                                      lr=0.01,\n",
        "                                      weight_decay=5e-4)\n",
        "\n",
        "        self.train()\n",
        "        for epoch in range(epochs+1):\n",
        "            optimizer.zero_grad()\n",
        "            out = self(data.x, adjacency)\n",
        "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "            acc = accuracy(out[data.train_mask].argmax(dim=1),\n",
        "                          data.y[data.train_mask])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if(epoch % 20 == 0):\n",
        "                val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
        "                val_acc = accuracy(out[data.val_mask].argmax(dim=1),\n",
        "                                  data.y[data.val_mask])\n",
        "                print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc:'\n",
        "                      f' {acc*100:>5.2f}% | Val Loss: {val_loss:.2f} | '\n",
        "                      f'Val Acc: {val_acc*100:.2f}%')\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def test(self, data):\n",
        "        self.eval()\n",
        "        out = self(data.x, adjacency)\n",
        "        acc = accuracy(out.argmax(dim=1)[data.test_mask], data.y[data.test_mask])\n",
        "        return acc\n",
        "\n",
        "# Create the Vanilla GNN model\n",
        "gnn = VanillaGNN(dataset.num_features, 16, dataset.num_classes)\n",
        "print(gnn)\n",
        "\n",
        "# Train\n",
        "gnn.fit(data, epochs=100)\n",
        "\n",
        "# Test\n",
        "acc = gnn.test(data)\n",
        "print(f'\\nGNN test accuracy: {acc*100:.2f}%')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Facebook Page-Page dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: FacebookPagePage()\n",
            "-----------------------\n",
            "Number of graphs: 1\n",
            "Number of nodes: 22470\n",
            "Number of features: 128\n",
            "Number of classes: 4\n",
            "\n",
            "Graph:\n",
            "------\n",
            "Edges are directed: False\n",
            "Graph has isolated nodes: False\n",
            "Graph has loops: True\n"
          ]
        }
      ],
      "source": [
        "## Facebook dataset\n",
        "from torch_geometric.datasets import FacebookPagePage\n",
        "\n",
        "# Import dataset from PyTorch Geometric\n",
        "dataset = FacebookPagePage(root=\"../../data/Facebook\")\n",
        "\n",
        "data = dataset[0]\n",
        "\n",
        "# Print information about the dataset\n",
        "print(f'Dataset: {dataset}')\n",
        "print('-----------------------')\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of nodes: {data.x.shape[0]}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')\n",
        "\n",
        "# Print information about the graph\n",
        "print(f'\\nGraph:')\n",
        "print('------')\n",
        "print(f'Edges are directed: {data.is_directed()}')\n",
        "print(f'Graph has isolated nodes: {data.has_isolated_nodes()}')\n",
        "print(f'Graph has loops: {data.has_self_loops()}')\n",
        "\n",
        "# Create masks\n",
        "data.train_mask = range(18000)\n",
        "data.val_mask = range(18001, 20000)\n",
        "data.test_mask = range(20001, 22470)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP(\n",
            "  (linear1): Linear(in_features=128, out_features=16, bias=True)\n",
            "  (linear2): Linear(in_features=16, out_features=4, bias=True)\n",
            ")\n",
            "Epoch   0 | Train Loss: 1.435 | Train Acc: 19.40% | Val Loss: 1.42 | Val Acc: 19.46%\n",
            "Epoch  20 | Train Loss: 0.677 | Train Acc: 73.54% | Val Loss: 0.69 | Val Acc: 73.04%\n",
            "Epoch  40 | Train Loss: 0.581 | Train Acc: 76.63% | Val Loss: 0.63 | Val Acc: 73.74%\n",
            "Epoch  60 | Train Loss: 0.551 | Train Acc: 78.13% | Val Loss: 0.61 | Val Acc: 75.14%\n",
            "Epoch  80 | Train Loss: 0.534 | Train Acc: 78.72% | Val Loss: 0.61 | Val Acc: 75.19%\n",
            "Epoch 100 | Train Loss: 0.522 | Train Acc: 79.26% | Val Loss: 0.61 | Val Acc: 75.59%\n",
            "\n",
            "MLP test accuracy: 75.42%\n",
            "\n",
            "VanillaGNN(\n",
            "  (gnn1): VanillaGNNLayer(\n",
            "    (linear): Linear(in_features=128, out_features=16, bias=False)\n",
            "  )\n",
            "  (gnn2): VanillaGNNLayer(\n",
            "    (linear): Linear(in_features=16, out_features=4, bias=False)\n",
            "  )\n",
            ")\n",
            "Epoch   0 | Train Loss: 46.270 | Train Acc: 25.39% | Val Loss: 46.26 | Val Acc: 25.41%\n",
            "Epoch  20 | Train Loss: 3.429 | Train Acc: 82.52% | Val Loss: 2.84 | Val Acc: 82.69%\n",
            "Epoch  40 | Train Loss: 1.318 | Train Acc: 84.51% | Val Loss: 1.28 | Val Acc: 85.04%\n",
            "Epoch  60 | Train Loss: 0.797 | Train Acc: 85.23% | Val Loss: 0.85 | Val Acc: 85.04%\n",
            "Epoch  80 | Train Loss: 0.690 | Train Acc: 85.83% | Val Loss: 0.72 | Val Acc: 85.39%\n",
            "Epoch 100 | Train Loss: 0.852 | Train Acc: 86.12% | Val Loss: 0.70 | Val Acc: 86.89%\n",
            "\n",
            "GNN test accuracy: 85.22%\n"
          ]
        }
      ],
      "source": [
        "# Dataset\n",
        "data.train_mask = range(18000)\n",
        "data.val_mask = range(18001, 20000)\n",
        "data.test_mask = range(20001, 22470)\n",
        "\n",
        "# Adjacency matrix\n",
        "adjacency = to_dense_adj(data.edge_index)[0]\n",
        "adjacency += torch.eye(len(adjacency))\n",
        "adjacency\n",
        "\n",
        "# MLP\n",
        "mlp = MLP(dataset.num_features, 16, dataset.num_classes)\n",
        "print(mlp)\n",
        "mlp.fit(data, epochs=100)\n",
        "acc = mlp.test(data)\n",
        "print(f'\\nMLP test accuracy: {acc*100:.2f}%\\n')\n",
        "\n",
        "# GCN\n",
        "gnn = VanillaGNN(dataset.num_features, 16, dataset.num_classes)\n",
        "print(gnn)\n",
        "gnn.fit(data, epochs=100)\n",
        "acc = gnn.test(data)\n",
        "print(f'\\nGNN test accuracy: {acc*100:.2f}%')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "book",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "vscode": {
      "interpreter": {
        "hash": "3556630122da5213751af4465d61fcf5a52cd22515d400aee51118aaa1721248"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "327acf50ddb34eb38feab845c8da82e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6f770342e9e403e9ab5f73623a8efb6",
            "placeholder": "​",
            "style": "IPY_MODEL_43717136a906424fb303ee45c7242116",
            "value": "Computing transition probabilities: 100%"
          }
        },
        "43717136a906424fb303ee45c7242116": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51dd30f90e234e4aa17374bf2c2419f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_327acf50ddb34eb38feab845c8da82e8",
              "IPY_MODEL_b0c83e7abab54f5792a37796cf195bc4",
              "IPY_MODEL_5983b3c6970644d183eb007ba105fcdb"
            ],
            "layout": "IPY_MODEL_c2aaf7ec538b49feaafbbe6962962454"
          }
        },
        "5983b3c6970644d183eb007ba105fcdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91af1f04a1dd4cadb4a231aa37d5af52",
            "placeholder": "​",
            "style": "IPY_MODEL_d9f1466ed11d479baf5878db3748cadb",
            "value": " 22470/22470 [01:34&lt;00:00, 203.42it/s]"
          }
        },
        "91af1f04a1dd4cadb4a231aa37d5af52": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "999663613ed7491b9a12992460611248": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0c83e7abab54f5792a37796cf195bc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_999663613ed7491b9a12992460611248",
            "max": 22470,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4fe165a8fcf4812b18f7ad54b7a7016",
            "value": 22470
          }
        },
        "b4fe165a8fcf4812b18f7ad54b7a7016": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2aaf7ec538b49feaafbbe6962962454": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9f1466ed11d479baf5878db3748cadb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6f770342e9e403e9ab5f73623a8efb6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
